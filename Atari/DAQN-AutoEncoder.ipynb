{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, random, os, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as tud\n",
    "from atari_wrappers import make_atari, wrap_deepmind,LazyFrames\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and wrap the environment\n",
    "env = make_atari('PongNoFrameskip-v4')\n",
    "env = wrap_deepmind(env, scale = False, frame_stack=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEMemory(object):\n",
    "    def __init__(self, memory_size=100000):\n",
    "        self.buffer = []\n",
    "        self.memory_size = memory_size\n",
    "        self.next_idx = 0\n",
    "        \n",
    "    def push(self, state):\n",
    "        state = state._force().transpose(2,0,1)[None]/255.\n",
    "        if len(self.buffer) <= self.memory_size: \n",
    "            self.buffer.append(state)\n",
    "        else: # buffer is full\n",
    "            self.buffer[self.next_idx] = state\n",
    "        self.next_idx = (self.next_idx + 1) % self.memory_size\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=8, stride=4), # bs*32*19*19\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2), # bs*64*9*9\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1), # bs*64*7*7\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.encoder_linear = nn.Sequential(\n",
    "            nn.Linear(7 * 7 * 64, 512), # bs*512\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, hidden_dim), # bs*hid_dim\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder_linear = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 512), # bs*512\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 7 * 7 * 64), # bs*64*7*7\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=1), # bs*64*9*9\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2), # bs*32*19*19\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, in_channels, kernel_size=8, stride=4) # bs*4*80*80\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        ## encoder\n",
    "        hidden = self.encoder_conv(x)\n",
    "        hidden = hidden.reshape(hidden.size(0),-1)\n",
    "        hidden = self.encoder_linear(hidden)\n",
    "        ## decoder\n",
    "        output = self.decoder_linear(hidden)\n",
    "        output = output.reshape(output.size(0),64,7,7)\n",
    "        output = self.decoder_conv(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill the memory\n",
    "memory = AEMemory(100000)\n",
    "\n",
    "for _ in tqdm(range(20)):\n",
    "    frame = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = random.randrange(env.action_space.n)\n",
    "        next_frame, _, done, _ = env.step(action)\n",
    "        memory.push(frame)\n",
    "        frame = next_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AutoEncoder Dataset\n",
    "class AEDataset(tud.Dataset):\n",
    "    def __init__(self,memory):\n",
    "        self.states = torch.Tensor(memory.buffer).squeeze(1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return self.states[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aedataset = AEDataset(memory)\n",
    "dataloader = tud.DataLoader(aedataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = AutoEncoder(in_channels = 4, hidden_dim = 6).to(device)\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-4)\n",
    "\n",
    "for e in range(20):\n",
    "    losses = []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = batch.to(device)\n",
    "        output = model(batch)\n",
    "        loss = loss_fn(batch, output)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    print(\"epoch:\", e, \"loss:\", round(np.mean(losses),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.encoder_conv,'saved_model/daqn_pre_conv')\n",
    "torch.save(model.encoder_linear,'saved_model/daqn_pre_linear')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
